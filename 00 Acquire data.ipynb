{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddd8a34e-c04c-4660-84bc-c1057ed9ec16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Raster acquisition, processing and analysis with Databricks\n",
    "\n",
    "Today we'll answer the biggest open question in the field of Earth observation and GIS systems:\n",
    "__which British golf course has the greenest, healthiest vegetation?__\n",
    "\n",
    "<img src='./assets/John-Daly-4.jpg'/>\n",
    "\n",
    "In this first notebook, we will demonstrate how to:\n",
    "- Install and configure a Databricks cluster ready for raster processing, including installing the Datbaricks Labs Mosaic[↗︎](https://github.com/databrickslabs/mosaic) project and its GDAL[↗︎](https://gdal.org/) extensions;\n",
    "- Read a publicly available vector dataset describing green space locations in Great Britain and prepare this for later use by reprojecting coordinates and converting the geometries into GeoJSON format;\n",
    "- Query the Microsoft Planetary Computer's Sentinel 2 catalog[↗︎](https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a) to obtain links to the relevant imagery for our areas of interest; and\n",
    "- Download the single-band GeoTIFF images to a location in the Databricks file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "469a50a3-a5d9-4094-a211-0fa60c8dbc09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Install the libraries and prepare the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa0e3cc4-5baf-48ad-be02-7d3b5c82ebd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For this demo we will require a few spatial libraries that can be easily installed via pip install. We will be using gdal, rasterio, pystac and databricks-mosaic for data download and data manipulation. We will use planetary computer as the source of the raster data for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e91dcc4-c4d1-4e6c-843b-1b644ac834ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "notebook_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "project_path = os.path.dirname(notebook_path)\n",
    "os.environ[\"PROJECTCWD\"] = project_path\n",
    "\n",
    "%pip install /Workspace$PROJECTCWD/databricks_mosaic-0.4.3-py3-none-any.whl\n",
    "%pip install --quiet rasterio==1.3.5 gdal==3.4.1 pystac pystac_client planetary_computer tenacity rich osdatahub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c915a766-8989-49c2-bd1d-eca453d6f2a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a33de043-55b7-4fe0-9356-56df486d963e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import library\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "import mosaic as mos\n",
    "\n",
    "from datetime import datetime\n",
    "from osdatahub import OpenDataDownload\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "data_product = \"OpenGreenspace\"\n",
    "\n",
    "current_user = spark.sql(\"select current_user() as user\").first()[\"user\"]\n",
    "data_root = f\"/tmp/{current_user}/{data_product}/data\"\n",
    "output_path = data_root.replace(\"/data\", \"/outputs\")\n",
    "\n",
    "dbutils.fs.mkdirs(data_root)\n",
    "dbutils.fs.mkdirs(output_path)\n",
    "\n",
    "os.environ[\"DATADIR\"] = f\"/dbfs{data_root}\"\n",
    "os.environ[\"OUTDIR\"] = f\"/dbfs{output_path}\"\n",
    "\n",
    "CATALOG = \"your_catalog\"\n",
    "SCHEMA = \"your_schema\"\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f1f5c01-7a97-44f3-8910-107518bccc78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1a. Acquire areas of interest (AoI) dataset\n",
    "For this example, we shall use a publicly available set of shape data: the [Ordnance Survey OpenGreenspace](https://www.ordnancesurvey.co.uk/products/os-open-greenspace) product. This dataset describes the locations of green spaces of various types across the British Isles.\n",
    "\n",
    "The dataset is available in multiple formats but we'll take the GeoPackage since that's usually a simple, reliable format to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "947d8d8e-aa86-4ad5-9593-26672098065e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "downloader = OpenDataDownload(data_product)\n",
    "os.environ[\"PRODUCT\"] = product_filename = \"opgrsp_gpkg_gb.zip\"\n",
    "downloader.download(output_dir=f\"/dbfs{data_root}\", file_name=product_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3341dd1d-0fcc-4c8e-9ac8-b10313e64db5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "mkdir -p $DATADIR/geopackage\n",
    "unzip -n $DATADIR/opgrsp_gpkg_gb.zip -d $DATADIR/geopackage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afbd05bc-7b0b-42e9-805f-393e8c1b6c71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh ls -lah $DATADIR/geopackage/Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e8688ca-eacb-4fc0-9371-39c93e020308",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1b. Read AoI data into Spark, reproject and store in Delta Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e29c1e34-1fe1-4677-86ee-25155591e1d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We will use Mosaic to read in this vector dataset, reproject it into a WGS84 coordinate reference system and write the feature geometries and their associated properties into a table in Unity Catalog.\n",
    "\n",
    "- Enabling Mosaic is a straightforward call to `mosaic.enable_mosaic()`.\n",
    "- If we want to use Mosaic's GDAL extensions (multiple vector and raster format readers, raster transformation functions etc.) then we also need to call `mosaic.enable_gdal()`.\n",
    "- GDAL needs to be installed and available on the cluster and Mosaic can also help us with this task (see instructions [here](https://databrickslabs.github.io/mosaic/usage/install-gdal.html))\n",
    "- The raster functions in Mosaic have two modes of operation. We'll opt for the more stable 'checkpointing enabled' mode, which persists intermediate raster results to a location in DBFS during execution of Spark jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d59192d9-2d44-4bb6-ad6b-dc3e4d92634b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"false\")\n",
    "mos.enable_mosaic(spark, dbutils)\n",
    "mos.enable_gdal(spark, with_checkpoint_path=f\"/dbfs{output_path}/checkpoint/{datetime.now().isoformat()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3ee13d3-5cbc-4cc4-83e6-b6693702d60f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Mosaic has specialised readers for geopackages, file geodatabases, shapefiles and other GDAL supported vector data formats (see [docs](https://databrickslabs.github.io/mosaic/api/vector-format-readers.html) for more info).\n",
    "\n",
    "It even has a mechanism for parallelising the read process by 'chunking' the source data and allocating a chunk of features to be read to a Spark task ([docs](https://databrickslabs.github.io/mosaic/api/vector-format-readers.html#mos-read-format-multi-read-ogr))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3cc4679-f192-4f11-aff1-0b84683682d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "green_spaces = (\n",
    "  mos.read().format(\"multi_read_ogr\")\n",
    "  .option(\"chunkSize\", \"500\")\n",
    "  .option(\"layerName\", \"greenspace_site\")\n",
    "  .load(f\"{data_root}/geopackage/Data/opgrsp_gb.gpkg\")\n",
    "  ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4adc3285-1f9a-4b8d-b608-b020eaaa7948",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "green_spaces.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bb90288-0559-4272-968a-04ff48282ae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For the purposes of this demo, we'll select one type of green space for our analysis (golf courses).\n",
    "\n",
    "The feature geometries are supplied in British National Grid projection. To make our data processing easier, we'll reproject this into EPSG:4326.\n",
    "\n",
    "Many of the feature geometries are compound geometries, i.e. `MULTIPOLYGON`. For the sake of keeping the task as simple as possible, we'll unpack these into their constituent parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f1e217-5a34-41a6-ad01-c6897340174d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aoi_type = \"Golf Course\"\n",
    "aoi_table_ref = f\"{CATALOG}.{SCHEMA}.aois\"\n",
    "\n",
    "aois = (\n",
    "  green_spaces\n",
    "  .where(F.col(\"function\") == aoi_type)\n",
    "  .withColumn(\"geometry_4326\", mos.st_updatesrid(\"geometry\", \"geometry_srid\", F.lit(4326)))\n",
    "  )\n",
    "aois.write.mode(\"overwrite\").saveAsTable(aoi_table_ref)\n",
    "aois = spark.table(aoi_table_ref)\n",
    "aois.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6419def2-7624-45ca-85a9-0a26dc98b7a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's go ahead and examine a subset of these using the excellent kepler.gl mapping tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f8a116c-7757-49c3-92c9-8452c511a259",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filter_geom = \"POLYGON (( -5.15 51.8, -4.9 51.8, -4.9 51.65, -5.15 51.65, -5.15 51.8 ))\"\n",
    "\n",
    "to_show = (\n",
    "  aois.select(\"id\", \"geometry_4326\")\n",
    "  .where(mos.st_intersects(\"geometry_4326\", F.lit(filter_geom)))\n",
    "  )\n",
    "\n",
    "to_show.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "15ea55d0-a429-4c89-890f-20d830344052",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here's an example of the map we'd expect to see if we run the following cell.\n",
    "<img src='./assets/wales-course.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e9113b3-be06-43d0-8d28-3594c0515577",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%mosaic_kepler\n",
    "to_show geometry_4326 geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac81ea5-ea3c-4887-b069-d5d73f3a60bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Acquire imagery from the Planetary Computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0addc6ff-4d14-4e66-bcf8-da0c95aa4cb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "It is fairly easy to interface with the pystac_client and remote raster data catalogs. We can browse resource collections and individual assets.\n",
    "\n",
    "For our search here, we'll take the geometries of our AoIs, express them as geojson and use them to query the catalog. A time range filter can also be supplied, as well as an upper bound on the level of cloud cover in the imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd1b19ae-1278-4a1a-b911-410a6c97ef0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "time_range = \"2021-05-01/2021-07-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19a81406-99e3-4bca-ae97-75875d67055e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "json_geoms = (\n",
    "  aois\n",
    "  .select(\"id\", \"geometry_4326\")\n",
    "  .withColumn(\"geojson\", mos.st_asgeojson(\"geometry_4326\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a24b2174-f14b-4748-a4cf-cc87a9fe94db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "json_geoms.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be24a15c-36d6-4061-908e-981cc3bfc283",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Our framework allows for easy preparation of stac requests with only one line of code. This data is delta ready as this point and can easily be stored for lineage purposes.\n",
    "\n",
    "For the purposes of this exercise, we'll retain the relationship between granules / sweeps and areas of interest by creating 'sets' of identifiers against each granule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c0beb7f-7dcc-4ff7-9038-ef86badb72b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eod_items = (\n",
    "  library.get_assets_for_cells(\n",
    "    json_geoms.repartition(sc.defaultParallelism),\n",
    "    time_range,\n",
    "    \"sentinel-2-l2a\"\n",
    "    )\n",
    "  .where(F.col(\"asset.type\") == \"image/tiff; application=geotiff; profile=cloud-optimized\")\n",
    "  .where(F.col(\"asset.name\") != \"preview\")\n",
    "  .groupBy(\"item_id\", \"asset.name\", \"item_properties.datetime\")\n",
    "  .agg(\n",
    "    F.collect_set(\"id\").alias(\"ids\"),\n",
    "    F.first(\"asset.href\").alias(\"href\"),\n",
    "    )\n",
    "  ).cache()\n",
    "eod_items.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcbb0b45-884e-4aaf-a36e-41eb260877e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eod_items.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32d02ee4-bfd1-49c2-866e-d9439dc58734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Download images into DBFS\n",
    "Now we have interrogated the catalogue, we can go ahead and directly download the imagery from the Planetary Computer storage account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97db5c63-ef7a-434a-bf99-28086d75ab50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "imagery_root = f\"/tmp/{current_user}/{data_product}/imagery\"\n",
    "dbutils.fs.mkdirs(imagery_root)\n",
    "\n",
    "imagery_table_ref = f\"{CATALOG}.{SCHEMA}.imagery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "babea4b6-c5f8-4a14-8802-6c676942b91b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "downloads = (\n",
    "  eod_items\n",
    "  .withColumn(\"downloaded_path\", library.download_asset(F.col(\"href\"), F.lit(f\"/dbfs{imagery_root}\")))\n",
    "  )\n",
    "downloads.write.mode(\"overwrite\").saveAsTable(imagery_table_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cf05099-7e8e-4eb1-8f94-d2ec0d415296",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.table(imagery_table_ref).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f9a3db8-f477-40c4-9e8e-b35b3af3e29d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.table(imagery_table_ref).count()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1152270835479399,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "00 Acquire data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
